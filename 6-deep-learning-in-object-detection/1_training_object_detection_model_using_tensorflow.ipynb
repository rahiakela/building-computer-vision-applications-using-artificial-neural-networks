{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-training-object-detection-model-using-tensorflow.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMwKjHKNrGQvSeObV8CdtBJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/building-computer-vision-applications-using-artificial-neural-networks/blob/master/6-deep-learning-in-object-detection/1_training_object_detection_model_using_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLAgkS5dxqXv"
      },
      "source": [
        "# Training Object Detection Model Using TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPFYKi-3x6lT"
      },
      "source": [
        "Object detection models are very compute-intensive and require both a lot of memory and a powerful processor. Most general-purpose laptops or computers may not be able to handle the computations necessary to build and train an object detection model.\n",
        "\n",
        "Thankfully, Google provides a limited amount of GPU-based computing\n",
        "for free. It has been proven that these models run many folds faster on a GPU than on a CPU. Therefore, it is important to learn how to train a model on a GPU.\n",
        "\n",
        "Let’s first define what our learning objective is and how we want to achieve it.\n",
        "\n",
        "- **Objective**: Learn how to train an object detection model using Keras\n",
        "and TensorFlow.\n",
        "- **Dataset**: The Oxford-IIIT Pet dataset, which is freely available at\n",
        "robots.ox.ac.uk/~vgg/data/pets/. The dataset consists of 37\n",
        "categories of pets with roughly 200 images for each class. The images\n",
        "have large variations in scale, pose, and lighting. They are already\n",
        "annotated with bounding boxes and labeled.\n",
        "\n",
        "- **Important note**: At the time of writing this book, TensorFlow version 2\n",
        "does not support the training of custom models for object detection.\n",
        "Therefore, we will use TensorFlow version 1.15 to train the model.\n",
        "The TensorFlow team and the open source community are working to migrate the version 1 code to support the training of custom object\n",
        "detection models in version 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7chFZGByvAI"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "berX4OAjywWX"
      },
      "source": [
        "Google Colab is an interactive programming environment and does not give direct\n",
        "access to the underlying operating system. You can invoke the shell using `%%shell`, which remains active within a single block of code cells it is invoked from. You can invoke the shell from as many code blocks as needed.\n",
        "\n",
        "To set up our environment, we will follow the following steps:\n",
        "\n",
        "1. Install the necessary libraries needed to execute our TensorFlow\n",
        "code and train our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh0askedoLb4"
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89DJBbH1zJz6"
      },
      "source": [
        "# Installing the Necessary Libraries and Packages\n",
        "%%shell\n",
        "%tensorflow_version 1.x\n",
        "sudo apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "pip install --user Cython\n",
        "pip install --user contextlib2\n",
        "pip install --user pillow\n",
        "pip install --user lxml\n",
        "pip install --user matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggF_mcsUz7-L"
      },
      "source": [
        "2. Download the TensorFlow “models” project from the GitHub repository, and build and install it in your working environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKPvps0YzqKK"
      },
      "source": [
        "# Downloading the TensorFlow Models Project, Building It, and Setting It Up\n",
        "%%shell\n",
        "mkdir computer_vision\n",
        "cd computer_vision\n",
        "git clone https://github.com/ansarisam/models.git\n",
        "# Official repository\n",
        "# git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "# The research directory contains a large number of models that are created and maintained by researchers and not officially supported yet.\n",
        "cd models/research\n",
        "\n",
        "# builds the object detection–related source code using the Protobuf compiler.\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# set the PYTHONPATH environment variable to the research and research/slim directories.\n",
        "export PYTHONPATH=$PYTHONPATH:/content/computer_vision/models/research\n",
        "export PYTHONPATH=$PYTHONPATH:/content/computer_vision/models/research/slim\n",
        "\n",
        "# executes a build command using setup.py\n",
        "python setup.py build\n",
        "# installs the object detection models in our working environment.\n",
        "python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVBSxXS514VA"
      },
      "source": [
        "## Downloading the Oxford-IIIT Pet Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VXDsiCJ15Gn"
      },
      "source": [
        "We will download the annotated and labeled pet dataset from the official website to a directory in our Colab workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDQ1E_9Vc460"
      },
      "source": [
        "# Downloading and Uncompressing the Images and Annotations of the Pet Dataset\n",
        "%%shell\n",
        "cd computer_vision\n",
        "mkdir petdata\n",
        "cd petdata\n",
        "wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "tar -xvf annotations.tar.gz\n",
        "tar -xvf images.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC0Xo-LEdoI_"
      },
      "source": [
        "## Generating TensorFlow TFRecord Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQosQfXLdpHO"
      },
      "source": [
        "TFRecord is a simple format for storing a sequence of binary records. The data in TFRecord is serialized and stored in smaller chunks (e.g., 100MB to 200MB), which makes them more efficient to transfer across networks and read serially. You will learn more about TFRecord, its format, and how to convert images and associated annotations in the TFRecord file format.\n",
        "\n",
        "Object detection algorithms take TFRecord files as input to the neural network.\n",
        "TensorFlow provides a Python script to convert the Oxford pet image annotation files to a set of TFRecord files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW1n9NgIdY6j"
      },
      "source": [
        "# Converting Image Annotation Files to TFRecord Files\n",
        "%%shell\n",
        "cd computer_vision/models/research\n",
        "\n",
        "python object_detection/dataset_tools/create_pet_tf_record.py \\\n",
        "       --label_map_path=object_detection/data/pet_label_map.pbtxt \\\n",
        "       --data_dir=/content/computer_vision/petdata \\\n",
        "       --output_dir=/content/computer_vision/petdata/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spB-Ne7xg79o"
      },
      "source": [
        "The Python script, create_pet_tf_record.py, that takes the following parameters:\n",
        "\n",
        "- **label_map_path**: This file has the mapping of an ID (starting from 1)\n",
        "and corresponding class name. For the pet dataset, the mapping file\n",
        "is already available in the object_detection/data/pet_label_map.\n",
        "pbtxt file.\n",
        "- **data_dir**: This is the parent directory of the images and annotations\n",
        "subdirectories.\n",
        "- **output_dir**: This is the destination directory where the TFRecord\n",
        "files will be stored. You can give any existing directory name. After\n",
        "conversion of images and annotations, the TFRecord files will be\n",
        "saved in this directory.\n",
        "\n",
        "After this executes, it creates a set of *.record files in the output_directory. The script, create_pet_tf_record.py, creates both training and evaluation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdnMorHTnGpD"
      },
      "source": [
        "## Downloading a Pre-trained Model for Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlhkVDpMnI-0"
      },
      "source": [
        "Training a state-of-the-art object detection model from scratch takes several days, even with GPUs. To speed up the training, we will download an existing model trained on a different dataset, such as COCO, and reuse some of its parameters, including the weights, to initialize our new model. Reusing the weights and parameters from a pre-trained model to train a new model is called transfer learning.\n",
        "\n",
        "A collection of object detection models, trained on COCO and other datasets, is\n",
        "located at “TensorFlow detection model zoo” (https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md).\n",
        "\n",
        "For our training, we will download the ssd_inception_v2_coco model from\n",
        "http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz. You can download any of the trained models and follow the rest of the steps to train your own model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIGlEXeRg0Sa",
        "outputId": "9f0f1015-559a-4c0a-e3fc-ead3cd758e4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Downloading a Pre-trained SSD Inception Object Detection Model\n",
        "%%shell\n",
        "cd computer_vision\n",
        "mkdir pre-trained-model\n",
        "cd pre-trained-model\n",
        "wget http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\n",
        "tar -xvf ssd_inception_v2_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-17 10:17:29--  http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.203.128, 2404:6800:4008:c04::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.203.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 278114232 (265M) [application/x-tar]\n",
            "Saving to: ‘ssd_inception_v2_coco_2018_01_28.tar.gz’\n",
            "\n",
            "ssd_inception_v2_co 100%[===================>] 265.23M  32.4MB/s    in 8.2s    \n",
            "\n",
            "2020-11-17 10:17:39 (32.4 MB/s) - ‘ssd_inception_v2_coco_2018_01_28.tar.gz’ saved [278114232/278114232]\n",
            "\n",
            "ssd_inception_v2_coco_2018_01_28/\n",
            "ssd_inception_v2_coco_2018_01_28/model.ckpt.index\n",
            "ssd_inception_v2_coco_2018_01_28/checkpoint\n",
            "ssd_inception_v2_coco_2018_01_28/pipeline.config\n",
            "ssd_inception_v2_coco_2018_01_28/model.ckpt.data-00000-of-00001\n",
            "ssd_inception_v2_coco_2018_01_28/model.ckpt.meta\n",
            "ssd_inception_v2_coco_2018_01_28/saved_model/\n",
            "ssd_inception_v2_coco_2018_01_28/saved_model/saved_model.pb\n",
            "ssd_inception_v2_coco_2018_01_28/saved_model/variables/\n",
            "ssd_inception_v2_coco_2018_01_28/frozen_inference_graph.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVtDVLPGtd14"
      },
      "source": [
        "## Configuring the Object Detection Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf4UNVD8teo0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPDUs2y3tZXj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}